//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31057947
// Cuda compilation tools, release 11.6, V11.6.124
// Based on NVVM 7.0.1
//

.version 7.6
.target sm_52
.address_size 64

	// .globl	_Z9intrinsicPf

.visible .entry _Z9intrinsicPf(
	.param .u64 _Z9intrinsicPf_param_0
)
{
	.reg .f32 	%f<5>;
	.reg .b64 	%rd<3>;


	ld.param.u64 	%rd1, [_Z9intrinsicPf_param_0];
	cvta.to.global.u64 	%rd2, %rd1;
	ld.global.f32 	%f1, [%rd2];
	lg2.approx.ftz.f32 	%f2, %f1;
	add.ftz.f32 	%f3, %f2, %f2;
	ex2.approx.ftz.f32 	%f4, %f3;
	st.global.f32 	[%rd2], %f4;
	ret;

}
	// .globl	_Z8standardPf
.visible .entry _Z8standardPf(
	.param .u64 _Z8standardPf_param_0
)
{
	.reg .pred 	%p<22>;
	.reg .f32 	%f<105>;
	.reg .b32 	%r<15>;
	.reg .b64 	%rd<3>;


	ld.param.u64 	%rd2, [_Z8standardPf_param_0];
	cvta.to.global.u64 	%rd1, %rd2;
	mov.f32 	%f17, 0f3F800000;
	cvt.rzi.f32.f32 	%f18, %f17;
	add.ftz.f32 	%f19, %f18, %f18;
	mov.f32 	%f20, 0f40000000;
	sub.ftz.f32 	%f21, %f20, %f19;
	abs.ftz.f32 	%f1, %f21;
	ld.global.f32 	%f2, [%rd1];
	abs.ftz.f32 	%f3, %f2;
	mov.b32 	%r1, %f3;
	and.b32  	%r2, %r1, 8388607;
	or.b32  	%r3, %r2, 1065353216;
	mov.b32 	%f22, %r3;
	shr.u32 	%r4, %r1, 23;
	cvt.rn.f32.u32 	%f23, %r4;
	add.ftz.f32 	%f24, %f23, 0fC2FE0000;
	setp.gt.ftz.f32 	%p2, %f22, 0f3FB504F3;
	mul.ftz.f32 	%f25, %f22, 0f3F000000;
	add.ftz.f32 	%f26, %f24, 0f3F800000;
	selp.f32 	%f27, %f26, %f24, %p2;
	selp.f32 	%f28, %f25, %f22, %p2;
	add.ftz.f32 	%f29, %f28, 0fBF800000;
	add.ftz.f32 	%f30, %f28, 0f3F800000;
	rcp.approx.ftz.f32 	%f31, %f30;
	add.ftz.f32 	%f32, %f29, %f29;
	mul.ftz.f32 	%f33, %f32, %f31;
	mul.ftz.f32 	%f34, %f33, %f33;
	mov.f32 	%f35, 0f3C4CAF63;
	mov.f32 	%f36, 0f3B18F0FE;
	fma.rn.ftz.f32 	%f37, %f36, %f34, %f35;
	mov.f32 	%f38, 0f3DAAAABD;
	fma.rn.ftz.f32 	%f39, %f37, %f34, %f38;
	mul.rn.ftz.f32 	%f40, %f39, %f34;
	mul.rn.ftz.f32 	%f41, %f40, %f33;
	sub.ftz.f32 	%f42, %f29, %f33;
	add.ftz.f32 	%f43, %f42, %f42;
	neg.ftz.f32 	%f44, %f33;
	fma.rn.ftz.f32 	%f45, %f44, %f29, %f43;
	mul.rn.ftz.f32 	%f46, %f31, %f45;
	add.ftz.f32 	%f47, %f41, %f33;
	sub.ftz.f32 	%f48, %f33, %f47;
	add.ftz.f32 	%f49, %f41, %f48;
	add.ftz.f32 	%f50, %f46, %f49;
	add.ftz.f32 	%f51, %f47, %f50;
	sub.ftz.f32 	%f52, %f47, %f51;
	add.ftz.f32 	%f53, %f50, %f52;
	mov.f32 	%f54, 0f3F317200;
	mul.rn.ftz.f32 	%f55, %f27, %f54;
	mov.f32 	%f56, 0f35BFBE8E;
	mul.rn.ftz.f32 	%f57, %f27, %f56;
	add.ftz.f32 	%f58, %f55, %f51;
	sub.ftz.f32 	%f59, %f55, %f58;
	add.ftz.f32 	%f60, %f51, %f59;
	add.ftz.f32 	%f61, %f53, %f60;
	add.ftz.f32 	%f62, %f57, %f61;
	add.ftz.f32 	%f63, %f58, %f62;
	sub.ftz.f32 	%f64, %f58, %f63;
	add.ftz.f32 	%f65, %f62, %f64;
	abs.ftz.f32 	%f4, %f20;
	setp.gt.ftz.f32 	%p3, %f4, 0f77F684DF;
	selp.f32 	%f66, 0f39800000, 0f40000000, %p3;
	mul.rn.ftz.f32 	%f67, %f66, %f63;
	neg.ftz.f32 	%f68, %f67;
	fma.rn.ftz.f32 	%f69, %f66, %f63, %f68;
	fma.rn.ftz.f32 	%f70, %f66, %f65, %f69;
	mov.f32 	%f71, 0f00000000;
	fma.rn.ftz.f32 	%f72, %f71, %f63, %f70;
	add.rn.ftz.f32 	%f73, %f67, %f72;
	neg.ftz.f32 	%f74, %f73;
	add.rn.ftz.f32 	%f75, %f67, %f74;
	add.rn.ftz.f32 	%f76, %f75, %f72;
	mov.b32 	%r5, %f73;
	setp.eq.s32 	%p4, %r5, 1118925336;
	add.s32 	%r6, %r5, -1;
	mov.b32 	%f77, %r6;
	add.ftz.f32 	%f78, %f76, 0f37000000;
	selp.f32 	%f5, %f78, %f76, %p4;
	selp.f32 	%f79, %f77, %f73, %p4;
	mov.f32 	%f80, 0f3FB8AA3B;
	mul.rn.ftz.f32 	%f81, %f79, %f80;
	cvt.rzi.f32.f32 	%f82, %f81;
	abs.ftz.f32 	%f83, %f82;
	setp.gt.ftz.f32 	%p5, %f83, 0f42FC0000;
	mov.b32 	%r7, %f82;
	and.b32  	%r8, %r7, -2147483648;
	or.b32  	%r9, %r8, 1123811328;
	mov.b32 	%f84, %r9;
	selp.f32 	%f85, %f84, %f82, %p5;
	mov.f32 	%f86, 0fBF317218;
	fma.rn.ftz.f32 	%f87, %f85, %f86, %f79;
	mov.f32 	%f88, 0f3102E308;
	fma.rn.ftz.f32 	%f89, %f85, %f88, %f87;
	mul.ftz.f32 	%f90, %f89, 0f3FB8AA3B;
	add.ftz.f32 	%f91, %f85, 0f4B40007F;
	mov.b32 	%r10, %f91;
	shl.b32 	%r11, %r10, 23;
	mov.b32 	%f92, %r11;
	ex2.approx.ftz.f32 	%f93, %f90;
	mul.ftz.f32 	%f6, %f93, %f92;
	setp.eq.ftz.f32 	%p6, %f6, 0f7F800000;
	mov.f32 	%f102, 0f7F800000;
	@%p6 bra 	$L__BB1_2;

	fma.rn.ftz.f32 	%f102, %f6, %f5, %f6;

$L__BB1_2:
	setp.lt.ftz.f32 	%p7, %f2, 0f00000000;
	setp.eq.ftz.f32 	%p8, %f1, 0f3F800000;
	and.pred  	%p1, %p7, %p8;
	setp.eq.ftz.f32 	%p9, %f2, 0f00000000;
	@%p9 bra 	$L__BB1_6;
	bra.uni 	$L__BB1_3;

$L__BB1_6:
	add.ftz.f32 	%f98, %f2, %f2;
	selp.f32 	%f104, %f98, 0f00000000, %p8;
	bra.uni 	$L__BB1_7;

$L__BB1_3:
	mov.b32 	%r12, %f102;
	xor.b32  	%r13, %r12, -2147483648;
	mov.b32 	%f94, %r13;
	selp.f32 	%f104, %f94, %f102, %p1;
	setp.geu.ftz.f32 	%p10, %f2, 0f00000000;
	@%p10 bra 	$L__BB1_7;

	cvt.rzi.f32.f32 	%f96, %f20;
	setp.eq.ftz.f32 	%p11, %f96, 0f40000000;
	@%p11 bra 	$L__BB1_7;

	mov.f32 	%f104, 0f7FFFFFFF;

$L__BB1_7:
	add.ftz.f32 	%f99, %f3, %f4;
	mov.b32 	%r14, %f99;
	setp.lt.s32 	%p13, %r14, 2139095040;
	@%p13 bra 	$L__BB1_14;

	setp.gtu.ftz.f32 	%p14, %f3, 0f7F800000;
	setp.gtu.ftz.f32 	%p15, %f4, 0f7F800000;
	or.pred  	%p16, %p14, %p15;
	@%p16 bra 	$L__BB1_13;
	bra.uni 	$L__BB1_9;

$L__BB1_13:
	add.ftz.f32 	%f104, %f2, 0f40000000;
	bra.uni 	$L__BB1_14;

$L__BB1_9:
	setp.eq.ftz.f32 	%p17, %f4, 0f7F800000;
	@%p17 bra 	$L__BB1_12;
	bra.uni 	$L__BB1_10;

$L__BB1_12:
	setp.gt.ftz.f32 	%p19, %f3, 0f3F800000;
	selp.f32 	%f100, 0f7F800000, 0f00000000, %p19;
	setp.eq.ftz.f32 	%p20, %f2, 0fBF800000;
	selp.f32 	%f104, 0f3F800000, %f100, %p20;
	bra.uni 	$L__BB1_14;

$L__BB1_10:
	setp.neu.ftz.f32 	%p18, %f3, 0f7F800000;
	@%p18 bra 	$L__BB1_14;

	selp.f32 	%f104, 0fFF800000, 0f7F800000, %p1;

$L__BB1_14:
	setp.eq.ftz.f32 	%p21, %f2, 0f3F800000;
	selp.f32 	%f101, 0f3F800000, %f104, %p21;
	st.global.f32 	[%rd1], %f101;
	ret;

}

